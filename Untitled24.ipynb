{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_6z2A1lq1V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63RsvwaEq4Pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imdb_scraper(id_list):\n",
        "  # DataFrame Columns (not in order)\n",
        "  rating = []\n",
        "  reviews = []\n",
        "  titles = []\n",
        "  username = []\n",
        "  found_useful = []\n",
        "  date = []\n",
        "  total_ratings = 0\n",
        "\n",
        "  for id in id_list:\n",
        "    url_short = f'http://www.imdb.com/title/{id}/'\n",
        "    url_reviews = url_short + 'reviews?ref_=tt_urv'\n",
        "    url_ratings = url_short + 'ratings?ref_=tturv_ql_4'\n",
        "\n",
        "\n",
        "    while True:\n",
        "      response = requests.get(url_reviews)\n",
        "      soup = BeautifulSoup(response.text, 'html.parser')\n",
        "      items = soup.find_all(class_='lister-item-content')\n",
        "\n",
        "      # Ratings page\n",
        "      page = request.get(url_ratings)\n",
        "      content = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "      total_ratings = list(content2.find(class_ = \"allText\"))\n",
        "      total_ratings = total_ratings[0]\n",
        "      total_ratings = re.findall(r'[0-9]+', total_ratings)\n",
        "      total_ratings = ''.join(total_ratings)\n",
        "      \n",
        "      # populate lists\n",
        "      for item in items:\n",
        "          reviews.append(item.find(class_ = \"text show-more__control\").get_text())\n",
        "          titles.append(item.find(class_ = \"title\").get_text())\n",
        "          username.append(item.find(class_ = \"display-name-link\").get_text())\n",
        "          found_useful.append(item.find(class_ = \"actions text-muted\").get_text())\n",
        "          date.append(item.find(class_ = \"review-date\").get_text())\n",
        "          try:\n",
        "              rating.append(item.find(class_=\"rating-other-user-rating\").find('span').text)\n",
        "          except:\n",
        "              rating.append('NaN')\n",
        "\n",
        "      # loading more data\n",
        "      load = soup.find(class_='load-more-data')\n",
        "      try:\n",
        "        key = load['data-key']\n",
        "      except:\n",
        "        break\n",
        "      url_reviews = url_short + '/reviews/_ajax?paginationKey=' + key\n",
        "\n",
        "  # create DataFrame\n",
        "  df = pd.DataFrame(\n",
        "        {\n",
        "            'review':reviews,\n",
        "            'rating':rating,\n",
        "            'title':titles,\n",
        "            'username':username,\n",
        "            'found_useful':found_useful,\n",
        "            'date':date,\n",
        "            'no. of ratings':total_ratings\n",
        "        })\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}